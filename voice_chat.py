# advanced_voice_chat.py
# Program de chat vocal cu Gemini AI - Sistem Audio Avansat (CU STREAMING TTS È™i AUTO-CALIBRARE)

import sys
import os
import json
import time
import threading
import queue
import asyncio
import re
from datetime import datetime
import warnings
import tempfile
import wave
import collections
import random

# ... (Sistemul de logging rÄƒmÃ¢ne neschimbat) ...
LOG_CONFIG = {
    "app": True, "config": True, "cleanup": True, "audio": False, "vad": True,
    "process": True, "transcription": True, "voice": True, "tts": True,
    "tts_debug": False, "echo": True, "mute": True, "gemini": True,
    "gemini_debug": True, "semafor": False,
}
START_TIME = time.time()
def log_timestamp(message, category="app"):
    if LOG_CONFIG.get(category, True):
        elapsed = time.time() - START_TIME
        print(f"[{elapsed:8.3f}s] {message}")


os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = "1"
os.environ["QT_ENABLE_HIGHDPI_SCALING"] = "1"
os.environ["QT_AUTO_SCREEN_SCALE_FACTOR"] = "1"

warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=UserWarning)

from PySide6.QtWidgets import (QApplication, QWidget, QVBoxLayout, QHBoxLayout, QLabel,
                               QLineEdit, QPushButton, QTextEdit, QGroupBox, QFormLayout,
                               QSlider, QMessageBox, QCheckBox, QTabWidget, QSpinBox, QDialog,
                               QDialogButtonBox, QComboBox)
from PySide6.QtCore import QThread, Signal, QObject, Qt, QTimer, Slot
from PySide6.QtGui import QColor, QFont, QScreen, QTextCursor
import google.generativeai as genai
from dotenv import load_dotenv
import edge_tts
import pygame
import speech_recognition as sr
import torch
import sounddevice as sd
import numpy as np
from PIL import ImageGrab

load_dotenv()


# ADAUGÄ‚ IMPORT È˜I VERIFICARE PENTRU LIBRÄ‚RIA MARKDOWN
try:
    import markdown
except ImportError:
    QMessageBox.critical(None, "LibrÄƒrie LipsÄƒ", "Te rog instaleazÄƒ librÄƒria 'markdown' folosind comanda: pip install markdown")
    sys.exit(1)

# =================================================================================
# â­ FUNCÈšIE NOUÄ‚ PENTRU CURÄ‚ÈšAREA FIÈ˜IERELOR TEMPORARE
# =================================================================================
def cleanup_temp_files():
    """È˜terge fiÈ™ierele temp_speech... orfane din folderul rÄƒdÄƒcinÄƒ."""
    log_timestamp("ğŸ§¹ [CLEANUP] Se cautÄƒ fiÈ™iere temporare vechi la pornire...", "cleanup")
    deleted_count = 0
    current_dir = os.getcwd()
    
    for filename in os.listdir(current_dir):
        # VerificÄƒm dacÄƒ fiÈ™ierul corespunde EXACT formatului nostru
        if filename.startswith("temp_speech_") and filename.endswith(".mp3"):
            full_path = os.path.join(current_dir, filename)
            if os.path.isfile(full_path):
                try:
                    os.remove(full_path)
                    log_timestamp(f"  -> È˜ters: {filename}", "cleanup")
                    deleted_count += 1
                except Exception as e:
                    log_timestamp(f"  -> âš ï¸ Eroare la È™tergerea {filename}: {e}", "cleanup")
    
    if deleted_count > 0:
        log_timestamp(f"âœ… [CLEANUP] CurÄƒÈ›enie finalizatÄƒ. {deleted_count} fiÈ™iere È™terse.", "cleanup")
    else:
        log_timestamp("âœ… [CLEANUP] Niciun fiÈ™ier temporar de È™ters.", "cleanup")


# ... (Clasa ContinuousVoiceWorker rÄƒmÃ¢ne neschimbatÄƒ) ...
class ContinuousVoiceWorker(QObject):
    """Worker pentru ascultare continuÄƒ cu Silero VAD (din main_app.py)"""
    
    language_lock_requested = Signal(str)
    speech_activity_changed = Signal(bool)
    pause_progress_updated = Signal(int)
    speech_time_updated = Signal(float)
    speech_timeout = Signal()
    
    transcription_ready = Signal(str)
    status_changed = Signal(str)
    calibration_done = Signal(float)
    audio_level_changed = Signal(float)
    speaker_identified = Signal(str, float)
    
    def __init__(self, threshold, pause_duration, margin_percent, max_speech_duration, enable_echo_cancellation, vad_model):
        super().__init__()
        self._is_running = False
        self._is_muted = False
        self.enable_echo_cancellation = enable_echo_cancellation
        self.enable_speaker_identification = False
        
        # --- BLOC MODIFICAT ---
        # Nu mai Ã®ncÄƒrcÄƒm modelul aici, Ã®l primim gata Ã®ncÄƒrcat
        self.vad_model = vad_model
        log_timestamp("ğŸ¤ [VAD INIT] Model VAD pre-Ã®ncÄƒrcat a fost primit.", "vad")
        # --- SFÃ‚RÈ˜IT BLOC MODIFICAT ---
        
        self.current_lock_mode = 'auto'
        self.primary_language = "ro-RO"
        self.secondary_language = "ro-RO"
        self.sample_rate = 16000
        self.frame_duration = 32
        self.frame_size = int(self.sample_rate * self.frame_duration / 1000)
        self.threshold = threshold
        self.pause_duration = pause_duration
        self.margin_percent = margin_percent
        self.max_speech_duration = max_speech_duration
        self.speech_threshold = 0.5
        self.silence_threshold = 0.3
        self.silence_frames_threshold = int((self.pause_duration * 1000) / self.frame_duration)
        self.MAX_SPEECH_FRAMES = int(self.max_speech_duration * 1000 / self.frame_duration)
        self.ring_buffer_size = int(self.sample_rate * 0.5)
        self.ring_buffer = collections.deque(maxlen=self.ring_buffer_size // self.frame_size)
        self.is_speech_active = False
        self.frames_since_silence = 0
        self.speech_frames = []
        self.last_ai_text = ""
        self.recognizer = sr.Recognizer()
        self.recognizer.energy_threshold = threshold
        log_timestamp("ğŸ¤ [VAD INIT] Silero VAD iniÈ›ializat", "vad")

    def set_primary_language(self, lang_code):
        if self.primary_language != lang_code:
            self.primary_language = lang_code
            log_timestamp(f"ğŸ—£ï¸ [TRANSCRIERE] Limba primarÄƒ setatÄƒ la: '{lang_code}'", "transcription")

    def set_last_ai_text(self, text):
        self.last_ai_text = text
        log_timestamp(f"ğŸ”Š [ECHO PROTECTION] Salvat text AI: '{text[:50]}...'", "echo")

    def set_muted(self, muted, is_ai_speaking=True):
        self._is_muted = muted
        if not muted:
            self.ring_buffer.clear()
            self.speech_frames = []
            self.is_speech_active = False
            log_timestamp("ğŸ—‘ï¸ [MUTING] Buffer-ul audio golit la unmute", "mute")
        
        if muted:
            if is_ai_speaking:
                log_timestamp("ğŸ”‡ [MUTING] Ascultare PAUSATÄ‚ (AI vorbeÈ™te)", "mute")
                self.status_changed.emit("ğŸ”‡ Pausat (AI vorbeÈ™te)")
            else:
                log_timestamp("ğŸ”‡ [MUTING] Ascultare PAUSATÄ‚", "mute")
                self.status_changed.emit("ğŸ§ Mut")
        else:
            log_timestamp("ğŸ”Š [MUTING] Ascultare RELUATÄ‚", "mute")
            self.status_changed.emit("âšª AÈ™tept sÄƒ vorbeÈ™ti...")

    def set_max_speech_duration(self, seconds):
        self.max_speech_duration = seconds
        self.MAX_SPEECH_FRAMES = int(seconds * 1000 / self.frame_duration)
        log_timestamp(f"ğŸ¤ [WORKER UPDATE] Durata maximÄƒ setatÄƒ la {seconds}s.", "vad")

    def is_echo(self, transcribed_text):
        if not self.enable_echo_cancellation: return False
        if not self.last_ai_text or not transcribed_text: return False
        ai_normalized = ''.join(c for c in self.last_ai_text.lower() if c.isalnum() or c.isspace())
        transcribed_normalized = ''.join(c for c in transcribed_text.lower() if c.isalnum() or c.isspace())
        ai_words = set(ai_normalized.split())
        transcribed_words = transcribed_normalized.split()
        if len(transcribed_words) == 0: return False
        common_words = sum(1 for word in transcribed_words if word in ai_words)
        similarity = common_words / len(transcribed_words)
        is_echo_detected = similarity > 0.75
        if is_echo_detected: log_timestamp(f"ğŸš« [ECHO DETECTAT] '{transcribed_text}'", "echo")
        return is_echo_detected

    def audio_callback(self, indata, frames, time_info, status):
        if status: log_timestamp(f"âš ï¸ [AUDIO] Status: {status}", "audio")
        audio_data = indata[:, 0].copy()
        rms = np.sqrt(np.mean(audio_data.astype(float)**2))
        if rms > 0:
            db_level = 20 * np.log10(rms) + 90
            self.audio_level_changed.emit(min(max(db_level * 50, 0), 10000))
        if self._is_muted: return
        audio_tensor = torch.from_numpy(audio_data).float()
        with torch.no_grad():
            speech_probability = self.vad_model(audio_tensor, self.sample_rate).item()
        is_speech = speech_probability > self.speech_threshold
        audio_int16 = (audio_data * 32767).astype(np.int16)
        self.ring_buffer.append(audio_int16)
        if is_speech:
            if not self.is_speech_active:
                self.is_speech_active = True
                self.speech_activity_changed.emit(True)
                self.pause_progress_updated.emit(100)
                log_timestamp("ğŸŸ¢ [VAD] Ãnceput vorbire detectat", "vad")
                self.frames_since_silence = 0
                self.speech_frames = list(self.ring_buffer)
                self.status_changed.emit("ğŸ”µ VorbeÈ™ti...")
            else:
                self.frames_since_silence = 0
                self.speech_frames.append(audio_int16)
                self.pause_progress_updated.emit(100)
        else:
            if self.is_speech_active:
                self.frames_since_silence += 1
                self.speech_frames.append(audio_int16)
                progress = 100 - int(100 * self.frames_since_silence / self.silence_frames_threshold)
                self.pause_progress_updated.emit(progress)
        if self.is_speech_active:
            timp_ramas = (self.MAX_SPEECH_FRAMES - len(self.speech_frames)) * self.frame_duration / 1000.0
            self.speech_time_updated.emit(timp_ramas)
        should_process_due_to_pause = self.is_speech_active and self.frames_since_silence >= self.silence_frames_threshold
        should_process_due_to_length = self.is_speech_active and len(self.speech_frames) >= self.MAX_SPEECH_FRAMES
        if should_process_due_to_pause or should_process_due_to_length:
            if should_process_due_to_length:
                log_timestamp("ğŸ”´ [VAD] Limita de timp atinsÄƒ! Procesare forÈ›atÄƒ.", "vad")
                self.speech_timeout.emit()
            else:
                log_timestamp(f"ğŸ”´ [VAD] SfÃ¢rÈ™it vorbire (pauzÄƒ).", "vad")
                self.speech_activity_changed.emit(False)
            self.speech_time_updated.emit(-1)
            self.process_captured_speech()
            self.is_speech_active = False
            self.frames_since_silence = 0
            self.speech_frames = []

    def process_captured_speech(self):
        if len(self.speech_frames) == 0: return
        temp_path = None
        try:
            audio_data = np.concatenate(self.speech_frames)
            duration = len(audio_data) / self.sample_rate
            if duration < 0.3:
                self.status_changed.emit("âšª AÈ™tept sÄƒ vorbeÈ™ti...")
                return
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
                temp_path = temp_wav.name
                with wave.open(temp_path, 'wb') as wf:
                    wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(self.sample_rate)
                    wf.writeframes(audio_data.tobytes())
            with sr.AudioFile(temp_path) as source:
                audio = self.recognizer.record(source)
            self.status_changed.emit("ğŸŸ¡ Transcriu...")
            text = None
            try:
                text = self.recognizer.recognize_google(audio, language=self.primary_language)
            except sr.UnknownValueError:
                self.status_changed.emit("âš ï¸ Nu am Ã®nÈ›eles")
                return
            except sr.RequestError as e:
                self.status_changed.emit(f"âš ï¸ Eroare API: {e}")
                return
            if text:
                if self.is_echo(text):
                    self.status_changed.emit("âšª AÈ™tept sÄƒ vorbeÈ™ti...")
                    return
                self.transcription_ready.emit(text)
        except Exception as e:
            log_timestamp(f"âŒ [PROCESS] Eroare Ã®n procesarea audio: {e}", "process")
            self.status_changed.emit("âš ï¸ Eroare procesare")
        finally:
            if temp_path and os.path.exists(temp_path):
                try: os.unlink(temp_path)
                except Exception: pass

    def run(self):
        log_timestamp("ğŸ¤ [SILERO VAD WORKER] Worker pornit", "vad")
        self._is_running = True
        self.status_changed.emit("âšª AÈ™tept sÄƒ vorbeÈ™ti...")
        try:
            with sd.InputStream(samplerate=self.sample_rate, channels=1, dtype='float32', blocksize=self.frame_size, callback=self.audio_callback):
                log_timestamp("âœ… [SILERO VAD WORKER] Stream audio pornit", "vad")
                while self._is_running:
                    sd.sleep(100)
        except Exception as e:
            log_timestamp(f"âŒ [SILERO VAD WORKER] EROARE CRITICÄ‚: {e}", "vad")
            self.status_changed.emit(f"âš ï¸ Eroare: {e}")
        finally:
            log_timestamp("ğŸ¤ [SILERO VAD WORKER] Worker oprit", "vad")

    def stop(self):
        self._is_running = False

# ... (Clasa StreamingTTSManager rÄƒmÃ¢ne neschimbatÄƒ) ...
class StreamingTTSSignals(QObject):
    all_sentences_finished = Signal()
    error_occurred = Signal(str)
    play_audio_file = Signal(str)

class StreamingTTSManager:
    def __init__(self):
        self.signals = StreamingTTSSignals()
        self.tts_queue = queue.Queue()
        self.audio_queue = queue.Queue()
        self.is_generating = False
        self.is_playing = False
        self._stop_requested = False
        self.generator_thread = None
        self.player_thread = None
        self.current_voice = "ro-RO-EmilNeural"
        self._playback_finished_event = None
        log_timestamp("ğŸ”Š [STREAMING TTS] Manager iniÈ›ializat", "tts")

    def start_speaking(self, text, voice_id):
        if self.is_generating:
            self.stop_all()
            time.sleep(0.3)
        self.current_voice = voice_id
        self._stop_requested = False
        sentences = self._split_into_sentences(text)
        for sentence in sentences: self.tts_queue.put(sentence)
        self.tts_queue.put(None)
        self._start_generator_worker()
        self._start_player_worker()

    def _split_into_sentences(self, text):
        clean_text = re.sub(r'\[EMOTION:\w+\]\s*', '', text)
        sentences = []
        current = ""
        for char in clean_text:
            current += char
            if char in '.!?':
                if current.strip(): sentences.append(current.strip())
                current = ""
        if current.strip(): sentences.append(current.strip())
        return sentences if sentences else [clean_text]

    def _start_generator_worker(self):
        if self.generator_thread and self.generator_thread.is_alive(): return
        self.is_generating = True
        self.generator_thread = threading.Thread(target=self._generator_worker, daemon=True)
        self.generator_thread.start()

    def _start_player_worker(self):
        if self.player_thread and self.player_thread.is_alive(): return
        self.is_playing = True
        self.player_thread = threading.Thread(target=self._player_worker, daemon=True)
        self.player_thread.start()

    def _generator_worker(self):
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            while not self._stop_requested:
                text_chunk = self.tts_queue.get()
                if text_chunk is None: break
                if text_chunk.strip(): loop.run_until_complete(self._generate_audio_file(text_chunk))
                self.tts_queue.task_done()
        except Exception as e:
            self.signals.error_occurred.emit(str(e))
        finally:
            self.audio_queue.put(None)
            self.is_generating = False

    async def _generate_audio_file(self, text):
        output_file = f"temp_speech_{int(time.time()*1000)}_{random.randint(1000,9999)}.mp3"
        try:
            communicate = edge_tts.Communicate(text, self.current_voice)
            await communicate.save(output_file)
            self.audio_queue.put(output_file)
        except Exception as e:
            if os.path.exists(output_file): os.remove(output_file)
            raise

    def _player_worker(self):
        try:
            while not self._stop_requested:
                audio_path = self.audio_queue.get()
                if audio_path is None: break
                self._playback_finished_event = threading.Event()
                self.signals.play_audio_file.emit(audio_path)
                self._playback_finished_event.wait()
                if os.path.exists(audio_path):
                    try: os.remove(audio_path)
                    except Exception: pass
                self.audio_queue.task_done()
        except Exception as e:
            self.signals.error_occurred.emit(str(e))
        finally:
            self.is_playing = False
            self.signals.all_sentences_finished.emit()

    def stop_all(self):
        self._stop_requested = True
        try:
            pygame.mixer.music.stop(); pygame.mixer.music.unload()
        except: pass
        if self._playback_finished_event and not self._playback_finished_event.is_set():
            self._playback_finished_event.set()
        while not self.tts_queue.empty():
            try: self.tts_queue.get_nowait()
            except: break
        while not self.audio_queue.empty():
            try:
                item = self.audio_queue.get_nowait()
                if item and os.path.exists(item): os.remove(item)
            except: break
        if self.generator_thread and self.generator_thread.is_alive(): self.generator_thread.join(timeout=1.0)
        if self.player_thread and self.player_thread.is_alive(): self.player_thread.join(timeout=1.0)
        self.is_generating = self.is_playing = False


class AdvancedVoiceChatApp(QWidget):
    gemini_response_signal = Signal(str)
    CONFIG_FILE = "voice_chat_config.json"
    
    def load_config(self):
        # --- MODIFICAT: AdÄƒugÄƒm noua setare de auto-calibrare ---
        default_config = {
            "threshold": 4000, "pause_duration": 1.5, "max_speech_duration": 15,
            "enable_echo_cancellation": True, "tts_enabled": True,
            "selected_voice": "ro-RO-EmilNeural",
            "custom_system_prompt": "EÈ™ti un asistent util È™i prietenos. RÄƒspunde concis È™i clar Ã®n limba romÃ¢nÄƒ.",
            "conversation_memory_limit": 10,
            "auto_calibrate_on_start": True,  # <-- SETARE AUTO-CALIBRARE
            "desktop_assistant_mode": False,  # <-- SETARE DESKTOP ASSISTANT
            "selected_model": "gemini-flash-latest"  # <-- MODEL AI SELECTAT
        }
        try:
            if os.path.exists(self.CONFIG_FILE):
                with open(self.CONFIG_FILE, 'r', encoding='utf-8') as f:
                    loaded_config = json.load(f)
                    default_config.update(loaded_config)
                log_timestamp("âœ… [CONFIG] ConfiguraÈ›ie Ã®ncÄƒrcatÄƒ din fiÈ™ier.", "config")
        except Exception as e:
            log_timestamp(f"âš ï¸ [CONFIG] Eroare la Ã®ncÄƒrcarea configuraÈ›iei: {e}. Se folosesc valori implicite.", "config")
        
        self.voice_config["threshold"] = default_config["threshold"]
        self.voice_config["pause_duration"] = default_config["pause_duration"]
        self.voice_config["max_speech_duration"] = default_config["max_speech_duration"]
        self.voice_config["enable_echo_cancellation"] = default_config["enable_echo_cancellation"]
        self.tts_enabled = default_config["tts_enabled"]
        self.selected_voice = default_config["selected_voice"]
        self.custom_system_prompt = default_config["custom_system_prompt"]  # Valoare implicit
        self.conversation_memory_limit = default_config["conversation_memory_limit"]
        self.auto_calibrate_on_start = default_config["auto_calibrate_on_start"] # <-- ÃNCÄ‚RCÄ‚M SETAREA
        self.desktop_assistant_mode = default_config["desktop_assistant_mode"] # <-- ÃNCÄ‚RCÄ‚M DESKTOP ASSISTANT
        self.selected_model = default_config["selected_model"]  # <-- ÃNCÄ‚RCÄ‚M MODELUL
        log_timestamp(f"âš™ï¸ [CONFIG] Auto-calibrare la pornire Ã®ncÄƒrcat: {self.auto_calibrate_on_start}", "config")
        log_timestamp(f"âš™ï¸ [CONFIG] Desktop Assistant Mode Ã®ncÄƒrcat: {self.desktop_assistant_mode}", "config")
        log_timestamp(f"ğŸ¤– [CONFIG] Model AI Ã®ncÄƒrcat: {self.selected_model}", "config")
    
    # --- FUNCÈšII NOI PENTRU PROMPT EXTERN ---
    PROMPT_FILE = "system_prompt.txt"
    
    def load_system_prompt(self):
        """ÃncarcÄƒ prompt-ul de sistem din fiÈ™ierul extern."""
        try:
            if os.path.exists(self.PROMPT_FILE):
                with open(self.PROMPT_FILE, 'r', encoding='utf-8') as f:
                    prompt_text = f.read().strip()
                    if prompt_text:
                        self.custom_system_prompt = prompt_text
                        log_timestamp(f"ğŸ“„ [PROMPT] Prompt Ã®ncÄƒrcat din {self.PROMPT_FILE} ({len(prompt_text)} caractere)", "config")
                        return True
                    else:
                        log_timestamp(f"âš ï¸ [PROMPT] FiÈ™ier {self.PROMPT_FILE} este gol, se foloseÈ™te prompt-ul implicit.", "config")
            else:
                log_timestamp(f"â„¹ï¸ [PROMPT] FiÈ™ier {self.PROMPT_FILE} nu existÄƒ, se creeazÄƒ cu prompt-ul implicit.", "config")
                self.save_system_prompt()
        except Exception as e:
            log_timestamp(f"âŒ [PROMPT] Eroare la Ã®ncÄƒrcarea prompt-ului: {e}", "config")
        return False
    
    def save_system_prompt(self):
        """SalveazÄƒ prompt-ul de sistem Ã®n fiÈ™ierul extern."""
        try:
            with open(self.PROMPT_FILE, 'w', encoding='utf-8') as f:
                f.write(self.custom_system_prompt)
            log_timestamp(f"ğŸ’¾ [PROMPT] Prompt salvat Ã®n {self.PROMPT_FILE} ({len(self.custom_system_prompt)} caractere)", "config")
            return True
        except Exception as e:
            log_timestamp(f"âŒ [PROMPT] Eroare la salvarea prompt-ului: {e}", "config")
            return False
    
    def reload_system_prompt(self):
        """ReÃ®ncarcÄƒ prompt-ul din fiÈ™ier È™i reiniÈ›ializeazÄƒ modelul."""
        if self.load_system_prompt():
            # ReiniÈ›ializÄƒm modelul cu noul prompt (folosim modelul selectat)
            self.model = genai.GenerativeModel(model_name=self.selected_model, system_instruction=self.custom_system_prompt)
            self.chat = self.model.start_chat(history=[])
            self.conversation_history = []
            
            # ActualizÄƒm preview-ul Ã®n interfaÈ›Äƒ
            preview_text = self.custom_system_prompt[:100] + "..." if len(self.custom_system_prompt) > 100 else self.custom_system_prompt
            self.prompt_preview.setText(f"Prompt actual: {preview_text}")
            
            log_timestamp("ğŸ”„ [PROMPT] Prompt reÃ®ncÄƒrcat È™i model reiniÈ›ializat!", "config")
            QMessageBox.information(self, "Succes", f"Prompt-ul a fost reÃ®ncÄƒrcat din {self.PROMPT_FILE}!\nConversaÈ›ia a fost resetatÄƒ.")
        else:
            QMessageBox.warning(self, "Eroare", f"Nu s-a putut reÃ®ncÄƒrca prompt-ul din {self.PROMPT_FILE}")
    # --- SFÃ‚RÈ˜IT FUNCÈšII NOI ---

    def save_config(self):
        config = {
            "threshold": self.voice_config["threshold"],
            "pause_duration": self.voice_config["pause_duration"],
            "max_speech_duration": self.voice_config["max_speech_duration"],
            "enable_echo_cancellation": self.voice_config["enable_echo_cancellation"],
            "tts_enabled": self.tts_enabled,
            "selected_voice": self.selected_voice,
            # custom_system_prompt NU mai e salvat aici - se salveazÄƒ Ã®n system_prompt.txt
            "conversation_memory_limit": self.conversation_memory_limit,
            "auto_calibrate_on_start": self.auto_calibrate_on_start, # <-- SALVÄ‚M AUTO-CALIBRARE
            "desktop_assistant_mode": self.desktop_assistant_mode,  # <-- SALVÄ‚M DESKTOP ASSISTANT
            "selected_model": self.selected_model  # <-- SALVÄ‚M MODELUL AI
        }
        try:
            with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=4, ensure_ascii=False)
            log_timestamp(f"ğŸ’¾ [CONFIG] Salvat: model={self.selected_model}, auto_calibrate={self.auto_calibrate_on_start}, desktop_mode={self.desktop_assistant_mode}", "config")
        except Exception as e:
            log_timestamp(f"âŒ [CONFIG] Eroare la salvarea configuraÈ›iei: {e}", "config")
    
    def __init__(self):
        super().__init__()
        
        # Verificare API Key (neschimbat)
        api_key = os.getenv("GOOGLE_API_KEY") or self._prompt_for_api_key()[0]
        if not api_key:
            QMessageBox.critical(self, "Eroare", "Cheia API Google Gemini este obligatorie!")
            sys.exit(1)
        try:
            genai.configure(api_key=api_key)
        except Exception as e:
            QMessageBox.critical(self, "Eroare", f"Cheia API nu este validÄƒ: {e}")
            sys.exit(1)
            
        # ÃncÄƒrcarea modelului VAD la pornire (neschimbat)
        log_timestamp("ğŸ§  [APP INIT] Se Ã®ncarcÄƒ modelul Silero VAD (o singurÄƒ datÄƒ)...", "app")
        try:
            torch.set_num_threads(1)
            self.vad_model, self.vad_utils = torch.hub.load(
                repo_or_dir='snakers4/silero-vad', model='silero_vad',
                force_reload=False, onnx=False)
        except Exception as e:
            QMessageBox.critical(self, "Eroare CriticÄƒ", f"Nu s-a putut Ã®ncÄƒrca modelul de detecÈ›ie vocalÄƒ:\n{e}\nAplicaÈ›ia se va Ã®nchide.")
            sys.exit(1)
            
        pygame.mixer.init()
        self.streaming_tts = StreamingTTSManager()
        
        # --- BLOC NOU ---
        self.desktop_assistant_mode = False
        os.makedirs("screenshots", exist_ok=True) # CreeazÄƒ folderul dacÄƒ nu existÄƒ
        # --- SFÃ‚RÈ˜IT BLOC NOU ---

        # --- MODELE AI DISPONIBILE ---
        self.available_models = {
            "Gemini Flash (Rapid)": "gemini-flash-latest",
            "Gemini Pro (Avansat)": "gemini-pro-latest"
        }
        # --- SFÃ‚RÈ˜IT MODELE ---

        self.romanian_voices = {"Emil (BÄƒrbat)": "ro-RO-EmilNeural", "Alina (Femeie)": "ro-RO-AlinaNeural"}
        self.voice_config = {"margin_percent": 25}
        self.load_config()
        
        # --- ÃNCÄ‚RCÄ‚M PROMPT-UL DIN FIÈ˜IER EXTERN ---
        self.load_system_prompt()
        # --- SFÃ‚RÈ˜IT ÃNCÄ‚RCARE PROMPT ---
        
        # Folosim modelul selectat din config
        self.model = genai.GenerativeModel(model_name=self.selected_model, system_instruction=self.custom_system_prompt)
        self.chat = self.model.start_chat(history=[])
        self.conversation_history = []
        self.voice_enabled = self.is_muted = False
        self.voice_worker = self.voice_thread = None
        self.gemini_response_signal.connect(self.display_gemini_response)
        self.streaming_tts.signals.all_sentences_finished.connect(self.on_all_sentences_finished)
        self.streaming_tts.signals.error_occurred.connect(self.on_streaming_tts_error)
        self.streaming_tts.signals.play_audio_file.connect(self.on_play_audio_file)
        self.pygame_check_timer = QTimer(self)
        self.pygame_check_timer.timeout.connect(self._check_pygame_playback)
        self.init_ui()
        
        # ActualizÄƒm preview-ul prompt-ului dupÄƒ ce UI-ul e creat
        preview_text = self.custom_system_prompt[:100] + "..." if len(self.custom_system_prompt) > 100 else self.custom_system_prompt
        self.prompt_preview.setText(f"Prompt actual: {preview_text}")

    def create_audio_tab(self):
        widget = QWidget()
        layout = QVBoxLayout(widget)
        controls_group = QGroupBox("ğŸ›ï¸ Controale Audio")
        controls_layout = QFormLayout()

        self.auto_calibrate_checkbox = QCheckBox("CalibreazÄƒ automat la pornire (recomandat)")
        self.auto_calibrate_checkbox.setChecked(self.auto_calibrate_on_start)
        self.auto_calibrate_checkbox.stateChanged.connect(self.on_auto_calibrate_changed)
        controls_layout.addRow(self.auto_calibrate_checkbox)
        
        self.threshold_slider = QSlider(Qt.Orientation.Horizontal)
        
        # --- MODIFICAT AICI ---
        self.threshold_slider.setRange(100, 12000)
        # --- SFÃ‚RÈ˜IT MODIFICARE ---
        
        self.threshold_slider.setValue(self.voice_config["threshold"])
        self.threshold_slider.valueChanged.connect(self.on_threshold_changed)
        self.threshold_label = QLabel(f"{self.voice_config['threshold']}")
        threshold_layout = QHBoxLayout()
        threshold_layout.addWidget(self.threshold_slider)
        threshold_layout.addWidget(self.threshold_label)
        controls_layout.addRow("Prag Energie (manual):", threshold_layout)
        
        # ... restul funcÈ›iei rÄƒmÃ¢ne neschimbat ...
        self.pause_slider = QSlider(Qt.Orientation.Horizontal)
        self.pause_slider.setRange(5, 50)
        self.pause_slider.setValue(int(self.voice_config["pause_duration"] * 10))
        self.pause_slider.valueChanged.connect(self.on_pause_changed)
        self.pause_label = QLabel(f"{self.voice_config['pause_duration']:.1f}s")
        pause_layout = QHBoxLayout()
        pause_layout.addWidget(self.pause_slider)
        pause_layout.addWidget(self.pause_label)
        controls_layout.addRow("PauzÄƒ SfÃ¢rÈ™it:", pause_layout)
        
        self.max_speech_slider = QSlider(Qt.Orientation.Horizontal)
        self.max_speech_slider.setRange(5, 30)
        self.max_speech_slider.setValue(self.voice_config["max_speech_duration"])
        self.max_speech_slider.valueChanged.connect(self.on_max_speech_changed)
        self.max_speech_label = QLabel(f"{self.voice_config['max_speech_duration']}s")
        max_speech_layout = QHBoxLayout()
        max_speech_layout.addWidget(self.max_speech_slider)
        max_speech_layout.addWidget(self.max_speech_label)
        controls_layout.addRow("DuratÄƒ Max Vorbire:", max_speech_layout)
        
        self.echo_checkbox = QCheckBox("Activat")
        self.echo_checkbox.setChecked(self.voice_config["enable_echo_cancellation"])
        self.echo_checkbox.stateChanged.connect(self.on_echo_changed)
        controls_layout.addRow("Anulare Ecou:", self.echo_checkbox)
        
        self.tts_checkbox = QCheckBox("Activat")
        self.tts_checkbox.setChecked(self.tts_enabled)
        self.tts_checkbox.stateChanged.connect(self.on_tts_changed)
        controls_layout.addRow("Text-to-Speech (TTS):", self.tts_checkbox)
        
        self.voice_combo = QComboBox()
        for voice_name in self.romanian_voices.keys():
            self.voice_combo.addItem(voice_name)
        for idx, (name, code) in enumerate(self.romanian_voices.items()):
            if code == self.selected_voice:
                self.voice_combo.setCurrentIndex(idx)
                break
        self.voice_combo.currentTextChanged.connect(self.on_voice_changed)
        controls_layout.addRow("Voce TTS RomÃ¢nÄƒ:", self.voice_combo)
        
        controls_group.setLayout(controls_layout)
        layout.addWidget(controls_group)
        layout.addStretch()
        widget.setLayout(layout)
        return widget

    # --- FUNCÈšIE NOUÄ‚: Handler pentru checkbox ---
    def on_auto_calibrate_changed(self, state):
        # AcelaÈ™i fix ca la Desktop Assistant - comparÄƒm cu valoarea integer
        self.auto_calibrate_on_start = (state == Qt.CheckState.Checked.value) or (state == 2)
        log_timestamp(f"âš™ï¸ [CONFIG] Calibrare automatÄƒ setatÄƒ la: {self.auto_calibrate_on_start}", "config")
        self.save_config()

    # --- FUNCÈšIE NOUÄ‚: Logica de calibrare ---
    def _run_auto_calibration(self):
        log_timestamp("ğŸ¤« [CALIBRARE] Se calibreazÄƒ pragul de energie... Stai Ã®n liniÈ™te 2s.", "app")
        self.update_status("ğŸ¤« Calibrez... LiniÈ™te 2s")
        QApplication.processEvents() # ForÈ›eazÄƒ actualizarea UI

        try:
            recognizer = sr.Recognizer()
            with sr.Microphone(sample_rate=16000) as source:
                recognizer.adjust_for_ambient_noise(source, duration=2)
            
            noise_level = recognizer.energy_threshold
            # Folosim o marjÄƒ fixÄƒ de 20% peste zgomot
            new_threshold = int(noise_level * 1.20) 
            
            # --- MODIFICAT AICI ---
            # Ne asigurÄƒm cÄƒ pragul nu e prea mic sau prea mare (pÃ¢nÄƒ la 12000)
            new_threshold = max(100, min(new_threshold, 12000))
            # --- SFÃ‚RÈ˜IT MODIFICARE ---

            log_timestamp(f"âœ… [CALIBRARE] Zgomot: {noise_level:.0f}, Prag nou: {new_threshold}", "app")
            
            # ActualizÄƒm valoarea Ã®n config È™i pe slider
            self.voice_config["threshold"] = new_threshold
            self.threshold_slider.setValue(new_threshold)
            self.update_status("âœ… Calibrare finalizatÄƒ!")
            QApplication.processEvents()
            time.sleep(1) # LasÄƒ utilizatorul sÄƒ vadÄƒ mesajul

        except Exception as e:
            log_timestamp(f"âŒ [CALIBRARE] Eroare: {e}", "app")
            self.update_status(f"âš ï¸ Eroare calibrare: {e}")
            time.sleep(2)

    def toggle_voice(self):
        """ActiveazÄƒ/dezactiveazÄƒ microfonul"""
        if not self.voice_enabled:
            if self.auto_calibrate_on_start:
                self._run_auto_calibration()

            self.voice_enabled = True
            self.voice_toggle_button.setText("ğŸ”´ OpreÈ™te Microfonul")
            self.voice_toggle_button.setStyleSheet("background-color: #e74c3c; font-size: 14px; padding: 10px; font-weight: bold;")
            self.mute_button.setEnabled(True)
            self.voice_thread = QThread(self)
            
            # --- MODIFICARE AICI: PasÄƒm modelul pre-Ã®ncÄƒrcat ---
            self.voice_worker = ContinuousVoiceWorker(
                threshold=self.voice_config["threshold"], 
                pause_duration=self.voice_config["pause_duration"],
                margin_percent=self.voice_config["margin_percent"], 
                max_speech_duration=self.voice_config["max_speech_duration"],
                enable_echo_cancellation=self.voice_config["enable_echo_cancellation"],
                vad_model=self.vad_model # <-- PARAMETRU NOU
            )
            
            # Atribuim È™i utilitarele, chiar dacÄƒ nu le folosim direct aici
            self.voice_worker.vad_utils = self.vad_utils
            # --- SFÃ‚RÈ˜IT MODIFICARE ---

            self.voice_worker.moveToThread(self.voice_thread)
            self.voice_worker.transcription_ready.connect(self.on_transcription_ready)
            self.voice_worker.status_changed.connect(self.update_status)
            self.voice_worker.speech_activity_changed.connect(self.on_speech_activity_changed)
            self.voice_worker.pause_progress_updated.connect(self.on_pause_progress_updated)
            self.voice_worker.speech_time_updated.connect(self.on_speech_time_updated)
            self.voice_worker.speech_timeout.connect(self.on_speech_timeout)
            self.voice_thread.started.connect(self.voice_worker.run)
            self.voice_thread.start()
        else:
            self.voice_enabled = False
            self.voice_toggle_button.setText("ğŸŸ¢ ActiveazÄƒ Microfonul")
            self.voice_toggle_button.setStyleSheet("background-color: #27ae60; font-size: 14px; padding: 10px; font-weight: bold;")
            self.mute_button.setEnabled(False)
            self.is_muted = False
            if self.voice_worker: self.voice_worker.stop()
            if self.voice_thread:
                self.voice_thread.quit()
                self.voice_thread.wait()
            self.update_status("Gata de conversaÈ›ie")
            self._update_semafor("rosu")
    
    
    def get_gemini_response(self, text):
        """ObÈ›ine rÄƒspuns de la Gemini, cu sau fÄƒrÄƒ screenshot, Ã®n funcÈ›ie de mod."""
        QTimer.singleShot(0, lambda: self.update_status("â³ AÈ™tept rÄƒspunsul..."))
        if self.voice_worker:
            self.voice_worker.set_muted(True, is_ai_speaking=True)
            
        try:
            full_response = ""
            
            # ADÄ‚UGÄ‚M textul user Ã®n istoric ÃNAINTE de request (comun pentru ambele moduri)
            self.conversation_history.append({"role": "user", "parts": [text]})
            log_timestamp(f"ğŸ’¾ [ISTORIC] Mesaj user adÄƒugat (total: {len(self.conversation_history)} mesaje)", "gemini")
            
            # TÄƒiem istoricul dacÄƒ e prea lung
            if len(self.conversation_history) > self.conversation_memory_limit * 2:
                self.conversation_history = self.conversation_history[-(self.conversation_memory_limit * 2):]
                log_timestamp(f"âœ‚ï¸ [ISTORIC] TÄƒiat la {self.conversation_memory_limit * 2} mesaje", "gemini")
            
            if self.desktop_assistant_mode:
                # --- MODUL ASISTENT DESKTOP (CU SCREENSHOT) ---
                log_timestamp("=" * 60, "app")
                log_timestamp("ğŸ¤– [ASSISTANT] MODUL ASISTENT DESKTOP ACTIVAT", "app")
                log_timestamp("=" * 60, "app")
                log_timestamp(f"ğŸ“ [ASSISTANT] Text user: '{text}'", "app")
                log_timestamp("ğŸ–¼ï¸ [ASSISTANT] Capturez ecranul...", "app")
                
                try:
                    # Preluarea geometriei monitorului principal
                    screen = QApplication.primaryScreen()
                    geometry = screen.geometry()
                    x, y, width, height = geometry.getRect()
                    log_timestamp(f"ğŸ“ [ASSISTANT] Dimensiuni: {width}x{height} @ ({x}, {y})", "app")
                    
                    # Capturarea screenshot-ului
                    screenshot = ImageGrab.grab(bbox=(x, y, x + width, y + height))
                    log_timestamp(f"âœ… [ASSISTANT] Screenshot capturat! Size: {screenshot.size}", "app")
                    
                    # Salvarea screenshot-ului
                    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S_%f")
                    filename = f"screenshot_{timestamp}.png"
                    save_path = os.path.join("screenshots", filename)
                    screenshot.save(save_path)
                    log_timestamp(f"ğŸ’¾ [ASSISTANT] Salvat: {save_path}", "app")
                    
                    # CreÄƒm model viziune - FOLOSIM MODELUL SELECTAT È˜I SYSTEM PROMPT-UL
                    # â­ ATENÈšIE: Aici este cheia! Folosim system_instruction din self.custom_system_prompt
                    vision_model = genai.GenerativeModel(
                        model_name=self.selected_model,
                        system_instruction=self.custom_system_prompt  # â­ ADAUGÄ‚ ACEASTÄ‚ LINIE!
                    )
                    model_name = "Flash" if "flash" in self.selected_model.lower() else "Pro"
                    log_timestamp(f"ğŸ¤– [ASSISTANT] Model Gemini {model_name} (viziune) init cu system prompt", "app")
                    
                    # CreÄƒm chat cu istoric TEXT-ONLY
                    chat_with_history = vision_model.start_chat(history=self.conversation_history[:-1])
                    log_timestamp(f"ğŸ“š [ASSISTANT] Chat cu {len(self.conversation_history)-1} mesaje istoric (text-only)", "gemini")
                    
                    # â­â­â­ MODIFICAREA CRITICÄ‚ - NU mai adÄƒugÄƒm instrucÈ›iuni forÈ›ate!
                    # Trimitem textul EXACT aÈ™a cum este, fÄƒrÄƒ instrucÈ›iuni suplimentare
                    # System prompt-ul se va ocupa de cÃ¢nd sÄƒ analizeze screenshot-ul
                    prompt_text = text  # â­ SIMPLIFICAT! Doar textul user, fÄƒrÄƒ instrucÈ›iuni extra
                    
                    log_timestamp(f"ğŸ“¤ [ASSISTANT] Trimit multimodal: text + screenshot (fÄƒrÄƒ instrucÈ›iuni forÈ›ate)", "gemini")
                    
                    # Trimitem mesajul CURENT cu screenshot
                    response_stream = chat_with_history.send_message(
                        [prompt_text, screenshot],
                        stream=True
                    )
                    
                    log_timestamp("â³ [ASSISTANT] Primesc rÄƒspuns (streaming)...", "gemini")
                    full_response = ""
                    chunk_count = 0
                    for chunk in response_stream:
                        if chunk.text:
                            full_response += chunk.text
                            chunk_count += 1
                            if chunk_count % 5 == 0:
                                log_timestamp(f"ğŸ“¦ [ASSISTANT] Chunk #{chunk_count}, total: {len(full_response)} chars", "gemini_debug")
                    
                    log_timestamp(f"âœ… [ASSISTANT] RÄƒspuns complet! {chunk_count} chunks, {len(full_response)} chars", "gemini")
                    log_timestamp(f"ğŸ’¬ [ASSISTANT] Preview: '{full_response[:150]}...'", "gemini_debug")
                    
                except Exception as screenshot_error:
                    log_timestamp(f"âŒ [ASSISTANT] EROARE: {screenshot_error}", "app")
                    import traceback
                    log_timestamp(f"ğŸ” [ASSISTANT] Traceback:\n{traceback.format_exc()}", "gemini_debug")
                    raise screenshot_error

            else:
                # --- MODUL NORMAL (TEXT-ONLY) ---
                log_timestamp(f"ğŸš€ [GEMINI] Modul normal (text-only)", "gemini")
                log_timestamp(f"ğŸ“ [GEMINI] Trimit: '{text}'", "gemini")
                
                self.chat = self.model.start_chat(history=self.conversation_history[:-1])
                log_timestamp(f"ğŸ“š [GEMINI] Chat cu {len(self.conversation_history)-1} mesaje istoric", "gemini")
                response_stream = self.chat.send_message(text, stream=True)
                full_response = "".join([chunk.text for chunk in response_stream if chunk.text])
                log_timestamp(f"âœ… [GEMINI] RÄƒspuns primit ({len(full_response)} chars)", "gemini")

            # --- LOGICA COMUNÄ‚: SalvÄƒm rÄƒspunsul AI Ã®n istoric (DOAR TEXT) ---
            self.conversation_history.append({"role": "model", "parts": [full_response]})
            log_timestamp(f"ğŸ’¾ [ISTORIC] RÄƒspuns AI salvat (total: {len(self.conversation_history)} mesaje)", "gemini")
            
            self.gemini_response_signal.emit(full_response)
            log_timestamp("ğŸ“¤ [GEMINI] Signal emis pentru afiÈ™are", "gemini_debug")
            
            if self.voice_worker:
                self.voice_worker.set_last_ai_text(full_response)
                log_timestamp("ğŸ”Š [ECHO] Text AI salvat pentru protecÈ›ie ecou", "echo")
            
            if self.tts_enabled:
                log_timestamp("ğŸ—£ï¸ [TTS] Pornesc TTS...", "tts")
                self.streaming_tts.start_speaking(full_response, self.selected_voice)
            else:
                log_timestamp("ğŸ”‡ [TTS] TTS off, reactivare microfon", "tts")
                self.on_all_sentences_finished()
                
        except Exception as e:
            log_timestamp(f"âŒ [GEMINI] EROARE CRITICÄ‚: {e}", "gemini")
            log_timestamp(f"ğŸ“‹ [GEMINI] Tip: {type(e).__name__}", "gemini")
            import traceback
            log_timestamp(f"ğŸ” [GEMINI] Traceback:\n{traceback.format_exc()}", "gemini_debug")
            error_msg = f"Eroare Gemini: {e}"
            QTimer.singleShot(0, lambda msg=error_msg: self.add_to_chat("Sistem", msg))
            self.on_all_sentences_finished()

    
    @Slot(str)
    def on_play_audio_file(self, audio_path):
        """RuleazÄƒ Ã®n main thread pentru a reda un fiÈ™ier audio cu pygame."""
        try:
            log_timestamp(f"ğŸµ [MAIN THREAD] Ãncep redare: '{audio_path}'", "tts")
            pygame.mixer.music.load(audio_path)
            pygame.mixer.music.play()
            
            # --- LINIE NOUÄ‚ ---
            self.stop_button.setEnabled(True) # ActivÄƒm butonul de stop
            
            self.pygame_check_timer.start(50) # VerificÄƒ la fiecare 50ms
        except Exception as e:
            log_timestamp(f"âŒ [MAIN THREAD] Eroare la pornire redare: {e}", "tts")
            if self.streaming_tts._playback_finished_event:
                self.streaming_tts._playback_finished_event.set()


    def _check_pygame_playback(self):
        if not pygame.mixer.music.get_busy():
            self.pygame_check_timer.stop()
            pygame.mixer.music.unload()
            if self.streaming_tts._playback_finished_event: self.streaming_tts._playback_finished_event.set()

    @Slot()
    def on_all_sentences_finished(self):
        """Callback apelat de manager cÃ¢nd TOATE propoziÈ›iile au fost redate."""
        log_timestamp("ğŸ [STREAMING] Toate propoziÈ›iile terminate. Se reactiveazÄƒ microfonul.", "tts")

        # --- LINIE NOUÄ‚ ---
        self.stop_button.setEnabled(False) # DezactivÄƒm butonul, nu mai are ce opri

        if self.voice_worker and not self.is_muted:
            self.voice_worker.set_muted(False, is_ai_speaking=False)
            log_timestamp("ğŸ”Š [UNMUTE] Microfon reactivat automat dupÄƒ TTS", "mute")
        elif self.is_muted:
            log_timestamp("ğŸ”‡ [UNMUTE] Mute manual activ - NU se reactiveazÄƒ microfonul", "mute")

    @Slot(str)
    def on_streaming_tts_error(self, error_message):
        self.streaming_tts.stop_all()
        self.on_all_sentences_finished()
    # ... [restul codului neschimbat] ...
    
    def _prompt_for_api_key(self):
        """Deschide un dialog, cere cheia API È™i o salveazÄƒ Ã®ntr-un fiÈ™ier .env."""
        from PySide6.QtWidgets import QInputDialog
        
        # Am actualizat textul pentru a fi mai clar pentru utilizator
        api_key, ok = QInputDialog.getText(
            self, 
            "Cheie API Google Gemini NecesarÄƒ",
            "Te rog introdu cheia API Google Gemini.\nAceasta va fi salvatÄƒ local Ã®ntr-un fiÈ™ier .env pentru a nu mai fi cerutÄƒ.",
            QLineEdit.EchoMode.Password
        )
        
        # VerificÄƒm dacÄƒ utilizatorul a apÄƒsat OK È™i a introdus ceva
        if ok and api_key.strip():
            api_key = api_key.strip()
            try:
                # CreÄƒm È™i scriem Ã®n fiÈ™ierul .env din folderul rÄƒdÄƒcinÄƒ
                with open(".env", "w", encoding="utf-8") as f:
                    f.write(f'GOOGLE_API_KEY="{api_key}"\n')
                log_timestamp("âœ… [API KEY] Cheia a fost salvatÄƒ cu succes Ã®n fiÈ™ierul .env.", "config")
            except IOError as e:
                # InformÄƒm utilizatorul dacÄƒ a apÄƒrut o eroare la scrierea fiÈ™ierului
                log_timestamp(f"âŒ [API KEY] Eroare la salvarea fiÈ™ierului .env: {e}", "config")
                QMessageBox.warning(self, "Eroare Salvare", f"Nu am putut salva cheia API Ã®n fiÈ™ierul .env.\nEroare: {e}\nVa trebui sÄƒ o introduci din nou data viitoare.")
        
        # ReturnÄƒm cheia È™i statusul pentru a fi folosite Ã®n sesiunea curentÄƒ
        return api_key, ok    

    def init_ui(self):
        self.setWindowTitle("ğŸ¤ Chat Vocal Avansat cu Gemini AI")
        self.setMinimumSize(900, 700)
        main_layout = QVBoxLayout()
        self.tabs = QTabWidget()
        conversation_tab = self.create_conversation_tab()
        audio_tab = self.create_audio_tab()
        ai_settings_tab = self.create_ai_settings_tab()
        self.tabs.addTab(conversation_tab, "ğŸ’¬ ConversaÈ›ie")
        self.tabs.addTab(audio_tab, "ğŸ¤ Audio")
        self.tabs.addTab(ai_settings_tab, "ğŸ¤– SetÄƒri AI")
        main_layout.addWidget(self.tabs)
        self.setLayout(main_layout)

    def create_conversation_tab(self):
        """CreeazÄƒ tab-ul principal de conversaÈ›ie"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # --- SECÈšIUNEA 1: SEMAFOR, STATUS È˜I ASISTENT DESKTOP ---
        status_layout = QHBoxLayout()
        
        # Grup Semafor (stÃ¢nga)
        semafor_group = QGroupBox("ğŸš¦ Semafor")
        semafor_layout = QHBoxLayout()
        
        # Semafor RoÈ™u
        rosu_container = QWidget()
        rosu_container_layout = QVBoxLayout(rosu_container)
        rosu_container_layout.setContentsMargins(0, 0, 0, 0)
        self.semafor_rosu = QLabel()
        self.semafor_rosu.setFixedSize(40, 40)
        self.semafor_rosu.setStyleSheet("background-color: #FF0000; border-radius: 20px;")
        rosu_container_layout.addWidget(self.semafor_rosu)
        
        # Semafor Galben (cu cronometru)
        galben_container = QWidget()
        galben_container_layout = QVBoxLayout(galben_container)
        galben_container_layout.setContentsMargins(0, 0, 0, 0)
        galben_container_layout.setSpacing(2)
        self.semafor_galben = QLabel()
        self.semafor_galben.setFixedSize(40, 40)
        self.semafor_galben.setStyleSheet("background-color: #4A3A00; border-radius: 20px;")
        self.cronometru_galben = QLabel("0.0")
        self.cronometru_galben.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.cronometru_galben.setStyleSheet("color: #FFA500; font-size: 10px; font-weight: bold;")
        self.cronometru_galben.hide()
        galben_container_layout.addWidget(self.semafor_galben)
        galben_container_layout.addWidget(self.cronometru_galben)
        
        # Semafor Verde (cu cronometru)
        verde_container = QWidget()
        verde_container_layout = QVBoxLayout(verde_container)
        verde_container_layout.setContentsMargins(0, 0, 0, 0)
        verde_container_layout.setSpacing(2)
        self.semafor_verde = QLabel()
        self.semafor_verde.setFixedSize(40, 40)
        self.semafor_verde.setStyleSheet("background-color: #004A00; border-radius: 20px;")
        self.cronometru_verde = QLabel("15")
        self.cronometru_verde.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.cronometru_verde.setStyleSheet("color: #00FF00; font-size: 10px; font-weight: bold;")
        self.cronometru_verde.hide()
        verde_container_layout.addWidget(self.semafor_verde)
        verde_container_layout.addWidget(self.cronometru_verde)
        
        semafor_layout.addWidget(rosu_container)
        semafor_layout.addWidget(galben_container)
        semafor_layout.addWidget(verde_container)
        semafor_group.setLayout(semafor_layout)
        
        # Grup Status (mijloc)
        status_group = QGroupBox("ğŸ“Š Status")
        status_inner_layout = QVBoxLayout(status_group)
        self.status_label = QLabel("Gata de pornire")
        self.status_label.setStyleSheet("color: #95a5a6; font-size: 14px; font-weight: bold;")
        status_inner_layout.addWidget(self.status_label)
        
        # Grup Asistent Desktop (dreapta) - NOU!
        assistant_group = QGroupBox("ğŸ¤– Desktop AI")
        assistant_inner_layout = QVBoxLayout(assistant_group)
        assistant_inner_layout.setContentsMargins(5, 5, 5, 5)
        
        self.desktop_assistant_checkbox = QCheckBox("ActiveazÄƒ")
        self.desktop_assistant_checkbox.setToolTip("CÃ¢nd este activat, la fiecare mesaj va fi ataÈ™at un screenshot al ecranului principal.")
        self.desktop_assistant_checkbox.setStyleSheet("font-size: 11px; font-weight: bold;")
        self.desktop_assistant_checkbox.setChecked(self.desktop_assistant_mode)
        self.desktop_assistant_checkbox.stateChanged.connect(self.on_desktop_assistant_toggled)
        assistant_inner_layout.addWidget(self.desktop_assistant_checkbox)
        
        # AdÄƒugÄƒm cele 3 grupuri Ã®n status_layout
        status_layout.addWidget(semafor_group)
        status_layout.addWidget(status_group, 1)  # stretch factor 1 - se Ã®ntinde
        status_layout.addWidget(assistant_group)  # dimensiune fixÄƒ
        
        # --- SECÈšIUNEA 2: BUTOANE CONTROL ---
        buttons_layout = QHBoxLayout()
        
        self.voice_toggle_button = QPushButton("ğŸŸ¢ ActiveazÄƒ Microfonul")
        self.voice_toggle_button.setStyleSheet("background-color: #27ae60; font-size: 14px; padding: 10px; font-weight: bold;")
        self.voice_toggle_button.clicked.connect(self.toggle_voice)
        
        self.stop_button = QPushButton("â¹ï¸ Stop Redare")
        self.stop_button.setStyleSheet("background-color: #c0392b; color: white; font-size: 14px; padding: 10px; font-weight: bold;")
        self.stop_button.clicked.connect(self.stop_audio_playback)
        self.stop_button.setEnabled(False)
        
        self.mute_button = QPushButton("ğŸ”‡ Mute")
        self.mute_button.setStyleSheet("background-color: #f39c12; font-size: 14px; padding: 10px; font-weight: bold;")
        self.mute_button.clicked.connect(self.toggle_mute)
        self.mute_button.setEnabled(False)
        
        buttons_layout.addWidget(self.voice_toggle_button)
        buttons_layout.addWidget(self.stop_button)
        buttons_layout.addWidget(self.mute_button)
        
        # --- SECÈšIUNEA 3: AFIÈ˜AJ CHAT ---
        chat_group = QGroupBox("ğŸ’¬ ConversaÈ›ie")
        chat_layout = QVBoxLayout(chat_group)
        
        self.chat_display = QTextEdit()
        self.chat_display.setReadOnly(True)


        # AdÄƒugÄƒm CSS pentru a formata blocurile de cod È™i a Ã®mbunÄƒtÄƒÈ›i aspectul general
        self.chat_display.document().setDefaultStyleSheet("""
            p { margin: 0; padding: 2px; }
            pre {
                background-color: #1e1e1e; /* Culoare de fundal similarÄƒ cu IDE-urile */
                color: #d4d4d4;           /* Culoare text deschisÄƒ */
                padding: 10px;
                border-radius: 5px;
                font-family: 'Courier New', Courier, monospace;
                white-space: pre-wrap;     /* AsigurÄƒ Ã®mpachetarea textului */
                display: block;
            }
            code {
                font-family: 'Courier New', Courier, monospace;
            }
        """)

        self.chat_display.setStyleSheet("background-color: #2c3e50; color: white; font-size: 12px; padding: 10px;")
        chat_layout.addWidget(self.chat_display)
        
        # --- SECÈšIUNEA 4: INPUT TEXT ---
        input_layout = QHBoxLayout()
        
        self.text_input = QLineEdit()
        self.text_input.setPlaceholderText("Scrie un mesaj sau foloseÈ™te microfonul...")
        self.text_input.setStyleSheet("font-size: 13px; padding: 8px;")
        self.text_input.returnPressed.connect(self.send_text_message)
        
        self.send_button = QPushButton("ğŸ“¤ Trimite")
        self.send_button.setStyleSheet("background-color: #3498db; color: white; font-size: 13px; padding: 8px 15px; font-weight: bold;")
        self.send_button.clicked.connect(self.send_text_message)
        
        input_layout.addWidget(self.text_input)
        input_layout.addWidget(self.send_button)
        
        # --- ASAMBLARE FINALÄ‚ LAYOUT ---
        layout.addLayout(status_layout)
        layout.addLayout(buttons_layout)
        layout.addWidget(chat_group, 1)
        layout.addLayout(input_layout)
        
        return widget

    @Slot(int)
    @Slot(int)
    def on_desktop_assistant_toggled(self, state):
        """ActiveazÄƒ sau dezactiveazÄƒ modul Asistent Desktop."""
        # DEBUG: Vedem ce primim exact
        log_timestamp(f"ğŸ” [DEBUG] Checkbox state primit: {state} (tip: {type(state)})", "app")
        log_timestamp(f"ğŸ” [DEBUG] Qt.CheckState.Checked = {Qt.CheckState.Checked} ({Qt.CheckState.Checked.value})", "app")
        log_timestamp(f"ğŸ” [DEBUG] Qt.CheckState.Unchecked = {Qt.CheckState.Unchecked} ({Qt.CheckState.Unchecked.value})", "app")
        
        # VerificÄƒm dacÄƒ state este 2 (Checked) - cea mai sigurÄƒ metodÄƒ
        self.desktop_assistant_mode = (state == Qt.CheckState.Checked.value) or (state == 2)
        
        mode_text = "activat" if self.desktop_assistant_mode else "dezactivat"
        log_timestamp(f"ğŸ¤– [ASSISTANT] Modul Asistent Desktop {mode_text}.", "app")
        log_timestamp(f"ğŸ” [DEBUG] desktop_assistant_mode setat la: {self.desktop_assistant_mode}", "app")
        self.save_config()  # <-- SALVÄ‚M CONFIGURAÈšIA


    @Slot()
    def stop_audio_playback(self):
        """OpreÈ™te forÈ›at redarea audio È™i reseteazÄƒ complet starea vocalÄƒ."""
        log_timestamp("â¹ï¸ [APP] Redarea audio a fost opritÄƒ manual de utilizator. Se reseteazÄƒ starea.", "app")
        
        # 1. OpreÈ™te sunetul
        self.streaming_tts.stop_all()
        
        # 2. OpreÈ™te complet modul vocal, dacÄƒ este activ
        if self.voice_enabled:
            # ApelÄƒm funcÈ›ia principalÄƒ de comutare pentru a executa oprirea completÄƒ
            # È™i a reseta corect interfaÈ›a graficÄƒ.
            self.toggle_voice()
        
        # 3. O mÄƒsurÄƒ de siguranÈ›Äƒ pentru a dezactiva butonul de stop
        self.stop_button.setEnabled(False)

    def create_ai_settings_tab(self):
        widget = QWidget()
        layout = QVBoxLayout()
        prompt_group = QGroupBox("ğŸ“ Personalitate AI")
        prompt_layout = QVBoxLayout()
        
        info_label = QLabel(f"DefineÈ™te personalitatea AI-ului prin intermediul unui system prompt.\nFiÈ™ier extern: <b>{self.PROMPT_FILE}</b> (poate fi editat direct)")
        info_label.setWordWrap(True)
        info_label.setStyleSheet("font-size: 11px; color: #666; margin-bottom: 5px;")
        prompt_layout.addWidget(info_label)
        
        # Layout pentru butoane (orizontal)
        buttons_layout = QHBoxLayout()
        
        self.edit_prompt_button = QPushButton("âœï¸ EditeazÄƒ Prompt")
        self.edit_prompt_button.setStyleSheet("background-color: #3498db; color: white; font-size: 13px; padding: 8px; font-weight: bold;")
        self.edit_prompt_button.clicked.connect(self.open_prompt_editor)
        buttons_layout.addWidget(self.edit_prompt_button)
        
        # BUTON NOU: ReÃ®ncarcÄƒ din fiÈ™ier
        self.reload_prompt_button = QPushButton("ğŸ”„ ReÃ®ncarcÄƒ din FiÈ™ier")
        self.reload_prompt_button.setStyleSheet("background-color: #27ae60; color: white; font-size: 13px; padding: 8px; font-weight: bold;")
        self.reload_prompt_button.setToolTip(f"ReÃ®ncarcÄƒ prompt-ul din {self.PROMPT_FILE}\n(util dacÄƒ ai editat fiÈ™ierul direct)")
        self.reload_prompt_button.clicked.connect(self.reload_system_prompt)
        buttons_layout.addWidget(self.reload_prompt_button)
        
        prompt_layout.addLayout(buttons_layout)
        
        self.prompt_preview = QLabel("Prompt actual: (se Ã®ncarcÄƒ...)")
        self.prompt_preview.setWordWrap(True)
        self.prompt_preview.setStyleSheet("font-size: 10px; color: #888; font-style: italic; padding: 5px; background-color: #f5f5f5; border-radius: 3px;")
        prompt_layout.addWidget(self.prompt_preview)
        
        prompt_group.setLayout(prompt_layout)
        
        # --- GRUP NOU: MODEL AI ---
        model_group = QGroupBox("ğŸ¤– Model AI")
        model_layout = QFormLayout()
        model_info = QLabel("SelecteazÄƒ modelul AI folosit pentru conversaÈ›ie:")
        model_info.setWordWrap(True)
        model_info.setStyleSheet("font-size: 11px; color: #666; margin-bottom: 5px;")
        model_layout.addRow(model_info)
        
        self.model_combo = QComboBox()
        for model_name in self.available_models.keys():
            self.model_combo.addItem(model_name)
        
        # SetÄƒm modelul curent din config
        for idx, (name, code) in enumerate(self.available_models.items()):
            if code == self.selected_model:
                self.model_combo.setCurrentIndex(idx)
                break
        
        self.model_combo.setStyleSheet("font-size: 12px; padding: 5px;")
        self.model_combo.currentTextChanged.connect(self.on_model_changed)
        model_layout.addRow("Model AI:", self.model_combo)
        
        # Descrieri modele
        model_desc = QLabel(
            "<b>Gemini Flash:</b> Rapid È™i eficient, ideal pentru conversaÈ›ii zilnice<br>"
            "<b>Gemini Pro:</b> Mai avansat, rÄƒspunsuri mai detaliate È™i complexe"
        )
        model_desc.setWordWrap(True)
        model_desc.setStyleSheet("font-size: 10px; color: #777; font-style: italic; margin-top: 5px;")
        model_layout.addRow(model_desc)
        
        model_group.setLayout(model_layout)
        # --- SFÃ‚RÈ˜IT GRUP MODEL AI ---
        
        memory_group = QGroupBox("ğŸ§  Memorie ConversaÈ›ie")
        memory_layout = QFormLayout()
        memory_info = QLabel("NumÄƒrul de schimburi de replici pe care AI-ul le pÄƒstreazÄƒ Ã®n memorie:")
        memory_info.setWordWrap(True)
        memory_info.setStyleSheet("font-size: 11px; color: #666; margin-bottom: 5px;")
        memory_layout.addRow(memory_info)
        self.memory_spinbox = QSpinBox()
        self.memory_spinbox.setRange(1, 50)
        self.memory_spinbox.setValue(10)
        self.memory_spinbox.setSuffix(" replici")
        self.memory_spinbox.setStyleSheet("font-size: 12px; padding: 5px;")
        self.memory_spinbox.valueChanged.connect(self.on_memory_changed)
        memory_layout.addRow("LimitÄƒ memorie:", self.memory_spinbox)
        memory_group.setLayout(memory_layout)
        layout.addWidget(prompt_group)
        layout.addWidget(model_group)  # <-- ADÄ‚UGÄ‚M GRUPA MODEL AI
        layout.addWidget(memory_group)
        layout.addStretch()
        widget.setLayout(layout)
        return widget


    def on_threshold_changed(self, value):
        self.voice_config["threshold"] = value
        self.threshold_label.setText(str(value))
        self.save_config()
    def on_pause_changed(self, value):
        self.voice_config["pause_duration"] = value / 10.0
        self.pause_label.setText(f"{value/10.0:.1f}s")
        if self.voice_worker:
            self.voice_worker.pause_duration = value / 10.0
            self.voice_worker.silence_frames_threshold = int((value / 10.0 * 1000) / self.voice_worker.frame_duration)
        self.save_config()
    def on_max_speech_changed(self, value):
        self.voice_config["max_speech_duration"] = value
        self.max_speech_label.setText(f"{value}s")
        if self.voice_worker:
            self.voice_worker.set_max_speech_duration(value)
        self.save_config()
    def on_echo_changed(self, state):
        self.voice_config["enable_echo_cancellation"] = (state == Qt.CheckState.Checked)
        if self.voice_worker:
            self.voice_worker.enable_echo_cancellation = self.voice_config["enable_echo_cancellation"]
        self.save_config()
    def toggle_mute(self):
        if not self.voice_worker: return
        self.is_muted = not self.is_muted
        if self.is_muted:
            self.mute_button.setText("ğŸŸ¢ ActiveazÄƒ")
            self.mute_button.setStyleSheet("background-color: #27ae60; font-size: 14px; padding: 10px; font-weight: bold;")
            self.voice_worker.set_muted(True, is_ai_speaking=False)
        else:
            self.mute_button.setText("ğŸ”‡ Mute")
            self.mute_button.setStyleSheet("background-color: #f39c12; font-size: 14px; padding: 10px; font-weight: bold;")
            self.voice_worker.set_muted(False, is_ai_speaking=False)
    def on_tts_changed(self, state):
        self.tts_enabled = (state == Qt.CheckState.Checked)
        self.save_config()
    def on_voice_changed(self, voice_name):
        self.selected_voice = self.romanian_voices[voice_name]
        self.save_config()
    def open_prompt_editor(self):
        dialog = QDialog(self)
        dialog.setWindowTitle("âœï¸ EditeazÄƒ Prompt-ul de Sistem")
        dialog.setMinimumSize(600, 400)
        layout = QVBoxLayout()
        
        info_label = QLabel(f"DefineÈ™te personalitatea È™i comportamentul AI-ului.\nFiÈ™ier: {self.PROMPT_FILE}")
        info_label.setWordWrap(True)
        layout.addWidget(info_label)
        
        prompt_editor = QTextEdit()
        prompt_editor.setPlainText(self.custom_system_prompt)
        layout.addWidget(prompt_editor)
        
        button_box = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        button_box.accepted.connect(dialog.accept)
        button_box.rejected.connect(dialog.reject)
        layout.addWidget(button_box)
        dialog.setLayout(layout)
        
        if dialog.exec() == QDialog.DialogCode.Accepted:
            new_prompt = prompt_editor.toPlainText().strip()
            if new_prompt:
                self.custom_system_prompt = new_prompt
                
                # SALVÄ‚M ÃN FIÈ˜IER EXTERN (nu mai salvÄƒm Ã®n config)
                if self.save_system_prompt():
                    # ReiniÈ›ializÄƒm modelul (folosim modelul selectat)
                    self.model = genai.GenerativeModel(model_name=self.selected_model, system_instruction=self.custom_system_prompt)
                    self.chat = self.model.start_chat(history=[])
                    self.conversation_history = []
                    
                    # ActualizÄƒm preview-ul
                    preview_text = new_prompt[:100] + "..." if len(new_prompt) > 100 else new_prompt
                    self.prompt_preview.setText(f"Prompt actual: {preview_text}")
                    
                    QMessageBox.information(self, "Succes", f"Prompt-ul a fost salvat Ã®n {self.PROMPT_FILE}!\nConversaÈ›ia a fost resetatÄƒ.\n\nPoÈ›i edita fiÈ™ierul direct cu orice editor de text.")
                else:
                    QMessageBox.warning(self, "Eroare", f"Nu s-a putut salva prompt-ul Ã®n {self.PROMPT_FILE}")
    def on_memory_changed(self, value):
        self.conversation_memory_limit = value
        self.save_config()
    
    def on_model_changed(self, model_name):
        """Handler pentru schimbarea modelului AI."""
        new_model = self.available_models[model_name]
        if new_model != self.selected_model:
            self.selected_model = new_model
            log_timestamp(f"ğŸ¤– [MODEL] Model schimbat la: {self.selected_model}", "config")
            
            # ReiniÈ›ializÄƒm modelul cu noul model selectat
            self.model = genai.GenerativeModel(model_name=self.selected_model, system_instruction=self.custom_system_prompt)
            self.chat = self.model.start_chat(history=[])
            self.conversation_history = []
            
            self.save_config()
            log_timestamp(f"âœ… [MODEL] Model reiniÈ›ializat. ConversaÈ›ia a fost resetatÄƒ.", "config")
            QMessageBox.information(self, "Model Schimbat", f"Modelul AI a fost schimbat la {model_name}.\nConversaÈ›ia a fost resetatÄƒ.")
    
    def send_text_message(self):
        text = self.text_input.text().strip()
        if not text: return
        self.add_to_chat("Tu", text)
        self.text_input.clear()
        threading.Thread(target=self.get_gemini_response, args=(text,), daemon=True).start()
    @Slot(str)
    def on_transcription_ready(self, text):
        self.add_to_chat("Tu", text)
        threading.Thread(target=self.get_gemini_response, args=(text,), daemon=True).start()
    @Slot(str)
    def display_gemini_response(self, response_text):
        self.add_to_chat("Gemini", response_text)
    @Slot(bool)
    def on_speech_activity_changed(self, is_speaking):
        if not self.voice_enabled: return
        if is_speaking: self._update_semafor("verde")
        else: self._update_semafor("galben")
    @Slot(int)
    def on_pause_progress_updated(self, progress):
        if not self.voice_enabled or not self.voice_worker: return
        if progress < 100 and self.voice_worker.is_speech_active:
            self._update_semafor("galben")
            timp_ramas = self.voice_config['pause_duration'] * progress / 100.0
            self.cronometru_galben.setText(f"{timp_ramas:.1f}")
            self.cronometru_galben.show()
        elif self.voice_worker.is_speech_active:
            self._update_semafor("verde")
    @Slot(float)
    def on_speech_time_updated(self, timp_ramas):
        if not self.voice_enabled: return
        if timp_ramas >= 0:
            self.cronometru_verde.setText(str(int(timp_ramas)))
            self.cronometru_verde.show()
        else:
            self.cronometru_verde.hide()
    @Slot()
    def on_speech_timeout(self):
        log_timestamp("â° [TIMEOUT] LimitÄƒ timp atinsÄƒ", "app")
    @Slot(str)
    def update_status(self, text):
        self.status_label.setText(text)
        if not self.voice_enabled:
            self._update_semafor("rosu")
            return
        if "AÈ™tept sÄƒ vorbeÈ™ti" in text or "VorbeÈ™ti" in text:
            self._update_semafor("verde")
        elif any(s in text for s in ["PauzÄƒ", "Pausat", "Transcriu", "AÈ™tept rÄƒspunsul"]):
            self._update_semafor("rosu")
    def _update_semafor(self, stare):
        self.semafor_rosu.setStyleSheet("background-color: #4A0000; border-radius: 20px;")
        self.semafor_verde.setStyleSheet("background-color: #004A00; border-radius: 20px;")
        self.semafor_galben.setStyleSheet("background-color: #4A3A00; border-radius: 20px;")
        if stare == "rosu":
            self.semafor_rosu.setStyleSheet("background-color: #FF0000; border-radius: 20px;")
            self.cronometru_verde.hide()
            self.cronometru_galben.hide()
        elif stare == "verde":
            self.semafor_verde.setStyleSheet("background-color: #00FF00; border-radius: 20px;")
            self.cronometru_verde.show()
            self.cronometru_galben.hide()
        elif stare == "galben":
            self.semafor_galben.setStyleSheet("background-color: #FFA500; border-radius: 20px;")
            self.cronometru_galben.show()
            self.cronometru_verde.hide()


    def add_to_chat(self, user, message):
        """AdaugÄƒ mesaj Ã®n chat cu formatare Markdown, culori È™i auto-scroll."""
        
        # MutÄƒ cursorul la sfÃ¢rÈ™itul documentului pentru a adÄƒuga conÈ›inut nou
        cursor = self.chat_display.textCursor()
        cursor.movePosition(QTextCursor.MoveOperation.End)
        self.chat_display.setTextCursor(cursor)

        # DeterminÄƒm culoarea È™i numele afiÈ™at Ã®n funcÈ›ie de utilizator
        if user == "Tu":
            color = "#2980b9"
            display_name = user
        elif user == "Gemini":
            color = "#8e44ad"
            model_display_name = "Flash" if "flash" in self.selected_model.lower() else "Pro"
            display_name = f"Gemini {model_display_name}"
        else:
            color = "#16a085"
            display_name = user

        # CreÄƒm antetul mesajului (ex: "Tu:", "Gemini Flash:")
        header_html = f"<b style='color:{color};'>{display_name}:</b>"

        # Convertim mesajul din Markdown Ã®n HTML.
        # 'fenced_code' - pentru blocuri de cod (```)
        # 'nl2br' - converteÈ™te newline-urile (\n) Ã®n tag-uri <br> pentru a pÄƒstra paragrafele
        message_html = markdown.markdown(message, extensions=['fenced_code', 'nl2br'])

        # InserÄƒm antetul È™i mesajul formatat
        # Folosim insertHtml pentru a pÄƒstra formatarea
        self.chat_display.insertHtml(f"{header_html}<br>{message_html}<br>")

        # AsigurÄƒm auto-scroll la ultimul mesaj
        self.chat_display.ensureCursorVisible()



    def closeEvent(self, event):
        log_timestamp("ğŸ›‘ Se Ã®nchide aplicaÈ›ia...", "app")
        self.save_config()
        self.streaming_tts.stop_all()
        if self.voice_worker: self.voice_worker.stop()
        if self.voice_thread:
            self.voice_thread.quit()
            self.voice_thread.wait()
        pygame.mixer.quit()
        event.accept()

if __name__ == "__main__":
    log_timestamp("=" * 60, "app")
    log_timestamp("ğŸ¤ CHAT VOCAL AVANSAT CU GEMINI AI (STREAMING) ğŸ¤", "app")
    log_timestamp("=" * 60, "app")
    
    cleanup_temp_files() # <-- AICI ESTE LINIA NOUÄ‚
    
    app = QApplication(sys.argv)
    window = AdvancedVoiceChatApp()
    window.show()
    sys.exit(app.exec())